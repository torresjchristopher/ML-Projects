# Training configuration for E2E ML pipeline
# Use this file to control data paths, model candidates, hyperparameter search space, and MLflow settings.

data:
  path: data/dataset.csv
  target: target    # replace with actual target column name (e.g., 'loan_status' or 'SeriousDlqin2yrs')
  test_size: 0.2
  random_state: 42

mlflow:
  tracking_uri: http://localhost:5000
  experiment_name: e2e-ml-experiments
  artifact_path: model

training:
  cv_folds: 5
  early_stopping_rounds: 50
  n_jobs: -1
  seed: 42

models:
  - name: xgboost
    enabled: true
    estimator: xgboost.XGBClassifier
    fit_params:
      use_label_encoder: false
      eval_metric: logloss
    search:
      type: random_search
      n_iter: 25
      param_distributions:
        n_estimators: [100, 200, 500]
        max_depth: [3, 5, 7, 9]
        learning_rate: [0.01, 0.05, 0.1, 0.2]
        subsample: [0.6, 0.8, 1.0]
        colsample_bytree: [0.6, 0.8, 1.0]
        reg_alpha: [0, 0.1, 1]
        reg_lambda: [1, 5, 10]

  - name: lightgbm
    enabled: true
    estimator: lightgbm.LGBMClassifier
    fit_params: {}
    search:
      type: random_search
      n_iter: 25
      param_distributions:
        n_estimators: [100, 200, 500]
        num_leaves: [31, 63, 127]
        learning_rate: [0.01, 0.05, 0.1]
        max_depth: [-1, 6, 10]
        subsample: [0.6, 0.8, 1.0]
        colsample_bytree: [0.6, 0.8, 1.0]

  - name: catboost
    enabled: true
    estimator: catboost.CatBoostClassifier
    fit_params:
      verbose: 0
    search:
      type: random_search
      n_iter: 25
      param_distributions:
        iterations: [200, 500]
        depth: [4, 6, 8]
        learning_rate: [0.01, 0.03, 0.1]
        l2_leaf_reg: [1, 3, 5]
        border_count: [32, 64, 128]

hyperopt:
  max_evals: 50
  seed: 42

logging:
  save_artifacts: true
  artifacts_dir: artifacts